{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"), temperature=0.7, model='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCHAIN_TRACING_V2=True\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_API_KEY=\"ls__95354472777f469dbda1536504c248fb\"\n",
    "LANGCHAIN_PROJECT=\"cogito\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "    c: int = Field(description=\"third number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"if there are only 2 numbers passed dont use it\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "    return_direct: bool = False\n",
    "    \n",
    "    \n",
    "\n",
    "    def _run(\n",
    "        self, a: int, b: int, c: int, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return a * b*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = CustomCalculatorTool(is_single_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if there are only 2 numbers passed dont use it'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Type1(BaseModel):\n",
    "    type: str = Field(description=\"Either chat or goals\")\n",
    "    message: str = Field(description=\"leave users message untouched here\")\n",
    "\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Type1)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages( [\n",
    "    (\n",
    "            \"system\",\n",
    "            \"You are an AI mentor that helps people stay motivated, so you store their goals. You need to decide whether the message you got from the user is about their specific goals, may be they want to add a new goal, or to extract an exisiting one, or whether they just want to chat. In the first case return just word goals. In other case return word chat. \\n{format_instructions} \\n The users message is following: {input} \"\n",
    "        ), \n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstChain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain11 = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaaain = firstChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain11.invoke({\"input\": \"i want to watch 1 leacture a day not 2\", \"format_instructions\":parser.get_format_instructions() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type1(type='goals', message='i want to watch 1 leacture a day not 2')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.get(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = parser.parse(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goals'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an AI mentor that helps people stay motivated, so you store their goals. You need to decide whether the message you got from the user is about their specific goals, may be they want to add a new goal, or to extract an exisiting one, or whether they just want to chat. \"\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "JustChatPrompt = ChatPromptTemplate.from_messages( [\n",
    "    (\n",
    "            \"system\",\n",
    "            \"You are an AI mentor that helps people stay motivated. Answer to the user according to this description. The users message is following: {input} \"\n",
    "        ), \n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChainJustChat = JustChatPrompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = await ChainJustChat.ainvoke({\"input\": \"hello how r u doing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm here and ready to help you stay motivated. How can I support you today?\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGoalData(BaseModel):\n",
    "    goal_name: str = Field(description=\"it is the name of the goal\")\n",
    "    goal_description: str = Field(description=\"Full description of a goal. Everything that you got from the user.\")\n",
    "    goal_end_state: str = Field(description=\"What should be done to consider a goal achieved.\")\n",
    "    user_id: int = Field(description=\"User's id passed by with the context\")\n",
    "\n",
    "class AddGoalTool(BaseTool):\n",
    "    name = \"Add users new goal to DB\"\n",
    "    description = \"If a user has provided all the required info to make a record about his new goal, then use this tool \"\n",
    "    args_schema: Type[BaseModel] = AddGoalData\n",
    "\n",
    "    def _run(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "\n",
    "     \n",
    "        return \"Just run\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Add goal to a DB. \"\"\"\n",
    "        pass\n",
    "        # If adding was succesfull return \"Goal added sucessfully\", else return \"Mistake, try adding goal again!\"\n",
    "        return \"Goal added sucessfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for adding goal agent\n",
    "AddingGoalAgentPrompt = ChatPromptTemplate.from_messages( [\n",
    "    (\n",
    "            \"system\",\n",
    "            \"You are an AI mentor that helps people stay motivated. User wants to add a new goal, therefore check a user\"+\n",
    "            \"has provided all the required info. Required info: description of the goal, end of goal (under what circumstances should the goal be considered finished and achieved). The id of the user if: {user_id}. Consider also chat history: {chat_history}. The users message is following: {input} \"\n",
    "        ), \n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = AddGoalTool()\n",
    "agent = create_tool_calling_agent(llm, tools= [tool ], prompt=AddingGoalAgentPrompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools= [tool], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent_executor.ainvoke({\"input\":\"hello\" ,\"user_id\": 505505})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object Chain.ainvoke at 0x1507c4340>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/dmitrii_sakharov/Docs/Cogito/test/test_agent.ipynb Ячейка 34\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dmitrii_sakharov/Docs/Cogito/test/test_agent.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output\u001b[39m.\u001b[39;49mcontent\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'coroutine' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='chat')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "model = llm\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"Either chat or goals\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    \n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"You are an AI mentor that helps people stay motivated, so you store their goals. You need to decide whether the message you got from the user is about their specific goals, may be they want to add a new goal, or to extract an exisiting one, or whether they just want to chat.\\n{format_instructions}\\n The users message is following: {query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | model\n",
    "output = prompt_and_model.invoke({\"query\": \"Lets talk about weather.\"})\n",
    "parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogito",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
